{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5d6a2e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62027 100000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from pyxdameraulevenshtein import damerau_levenshtein_distance_seqs\n",
    "from tqdm import tqdm\n",
    "data = []\n",
    "queries = []\n",
    "\n",
    "with open('dict.txt', 'r') as file:\n",
    "    data = [line.strip() for line in file]\n",
    "\n",
    "with open('queries.txt', 'r') as file:\n",
    "    queries = [line.strip() for line in file]\n",
    "print(len(data), len(queries))\n",
    "\n",
    "alphabet = ''.join(sorted(set(''.join(data))))\n",
    "def get_vector(word,alphabet):\n",
    "    result = [0]*len(alphabet)\n",
    "    for char in word:\n",
    "        result[alphabet.index(char)] += 1\n",
    "    return result\n",
    "\n",
    "# Convert to numpy array for faster processing\n",
    "vectorized_data = np.array([get_vector(word, alphabet) for word in data])\n",
    "\n",
    "# Optimized version using NumPy\n",
    "def get_words_with_distance(query_vector, vectorized_data, threshold):\n",
    "    # Convert query_vector to numpy array if it's not already\n",
    "    query_vector = np.array(query_vector).reshape(1, -1)\n",
    "    \n",
    "    # Calculate Manhattan distances between query and all words at once\n",
    "    distances = manhattan_distances(query_vector, vectorized_data)[0]\n",
    "    \n",
    "    # Return indices where distance is less than or equal to threshold\n",
    "    return np.where(distances <= threshold)[0].tolist()\n",
    "\n",
    "# Alternative version using scipy's cdist\n",
    "def get_words_with_distance_scipy(query_vector, vectorized_data, threshold):\n",
    "    query_vector = np.array(query_vector).reshape(1, -1)\n",
    "    # Calculate Manhattan distances\n",
    "    distances = cdist(query_vector, vectorized_data, metric='cityblock')[0]\n",
    "    # Return indices where distance is less than or equal to threshold\n",
    "    return np.where(distances <= threshold)[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd66bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correction_path(word1, word2, max_dist):\n",
    "    if word1 == word2:\n",
    "        return f\"{word1} 0\"\n",
    "    \n",
    "    from collections import deque\n",
    "    \n",
    "    queue = deque()\n",
    "    queue.append((word1, [word1], max_dist))\n",
    "    visited = set([word1])\n",
    "    \n",
    "    while queue:\n",
    "        current, path, remaining = queue.popleft()\n",
    "        \n",
    "        if current == word2:\n",
    "            ans = f\"{word1} {max_dist} {' '.join(path[1:])}\"\n",
    "            return ans\n",
    "        if remaining == 0:\n",
    "            continue\n",
    "        \n",
    "        length = len(current)\n",
    "        # Generate neighbors (all possible 1-step corrections)\n",
    "        neighbors = set()\n",
    "        \n",
    "        # Deletions\n",
    "        for i in range(length):\n",
    "            new_word = current[:i] + current[i+1:]\n",
    "            neighbors.add(new_word)\n",
    "        \n",
    "        # Insertions (only try inserting letters from target word)\n",
    "        for i in range(length + 1):\n",
    "            if i < len(word2):\n",
    "                new_word = current[:i] + word2[i] + current[i:]\n",
    "                neighbors.add(new_word)\n",
    "        \n",
    "        # Substitutions (only try substituting with target letters)\n",
    "        for i in range(min(length, len(word2))):\n",
    "            if current[i] != word2[i]:\n",
    "                new_word = current[:i] + word2[i] + current[i+1:]\n",
    "                neighbors.add(new_word)\n",
    "        \n",
    "        # Transpositions (only adjacent swaps that match target)\n",
    "        for i in range(length - 1):\n",
    "            if (i + 1 < len(word2) and \n",
    "                current[i] == word2[i+1] and \n",
    "                current[i+1] == word2[i]):\n",
    "                new_word = current[:i] + current[i+1] + current[i] + current[i+2:]\n",
    "                neighbors.add(new_word)\n",
    "        \n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append((neighbor, path + [neighbor], remaining - 1))\n",
    "    \n",
    "    return f\"{word1} {max_dist}+ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0068d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [06:02<00:00, 275.91it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('results.txt', 'w') as file:\n",
    "    for query in tqdm(queries):\n",
    "        vectorized_query = get_vector(query, alphabet)\n",
    "        candidates = get_words_with_distance_scipy(vectorized_query, vectorized_data, 4)\n",
    "        if len(candidates) > 0:\n",
    "            candidates = [data[i] for i in candidates]\n",
    "            distances = damerau_levenshtein_distance_seqs(query, candidates)\n",
    "            match, dist = candidates[np.argmin(distances)], min(distances)\n",
    "            correct_path = find_correction_path(query, match, dist)\n",
    "        else:\n",
    "            file.write(f'{query} 5+\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
